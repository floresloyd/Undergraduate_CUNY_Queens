---
title: "Lab 5 MATH 342W"
author: "Loyd Flores"
output: pdf_document
date: "11:59PM March 12"
---

Write a function spec'd as follows:

```{r}
#' Orthogonal Projection
#'
#' Projects vector a onto v.
#'
#' @param a   the vector to project
#' @param v   the vector projected onto
#'
#' @returns   a list of two vectors, the orthogonal projection parallel to v named a_parallel, 
#'            and the orthogonal error orthogonal to v called a_perpendicular
orthogonal_projection = function(a, v){
  a_parallel = (t(t(v)) %*% t(v) / (sum(v^2))) %*% a
  list(a_parallel = a_parallel, a_perpendicular = a - a_parallel)
}
```

Provide predictions for each of these computations and then run them to make sure you're correct.

```{r}
orthogonal_projection(c(1,2,3,4), c(1,2,3,4))
#prediction:
orthogonal_projection(c(1, 2, 3, 4), c(0, 2, 0, -1))
#prediction:
result = orthogonal_projection(c(2, 6, 7, 3), c(1, 3, 5, 7))
t(result$a_parallel) %*% result$a_perpendicular
#prediction:
result$a_parallel + result$a_perpendicular
#prediction:
result$a_parallel / c(1, 3, 5, 7)
#prediction:
```



Create a vector y by simulating n = 100 standard iid normals. Create a matrix of size 100 x 2 and populate the first column by all ones (for the intercept) and the second column by 100 standard iid normals. Find the R^2 of an OLS regression of `y ~ X`. Use matrix algebra.

```{r}
#TO-DO
n = 100
y = rnorm(n=n)
X = cbind(1, rnorm(n=n))
y_hat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
y_bar = mean(y_hat)

SSR = sum((y_hat - y_bar)^2)
SST = sum((y - y_bar)^2)
RSQ = SSR/SST

print(RSQ)
```

Write a for loop to each time bind a new column of 100 standard iid normals to the matrix X and find the R^2 each time until the number of columns is 100. Create a vector to save all R^2's. What happened??

```{r}
#TO-DO
rsqs = array(NA, n)
rsqs[2] = RSQ 
rsqs
for(j in 3:n){
  X = cbind(X, rnorm(n))  # adding more columns
  y_hat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
  SSR = sum((y_hat - y_bar)^2)
  SST = sum((y - y_bar)^2)
  rsqs [j] = SSR/SST
}
rsqs
```

Test that the projection matrix onto this X is the same as I_n. You may have to vectorize the matrices in the `expect_equal` function for the test to work.

```{r}
pacman::p_load(testthat)
#TO-DO
expect_equal(X %*% solve(t(X) %*% X) %*% t(X) , diag(n))

```

Add one final column to X to bring the number of columns to 101. Then try to compute R^2. What happens? 

```{r}
#TO-DO
# X = cbind(X, rnorm(n=n))
# y_hat = X %*% solve(t(X) %*% X) %*% t(X) %*% y
```

Why does this make sense?

#TO-DO

We can't perform this cause this operation fails because the matrix does is not full rank anymore. X(X^TX)^-1 (y). We also can only add up to n-(p+1)

Let's use the Boston Housing Data for the following exercises

```{r}
y = MASS::Boston$medv
X = model.matrix(medv ~ ., MASS::Boston) # RETURNS EVERYTHING BUT Y && ~. adds the 1 matrix 
p_plus_one = ncol(X)
n = nrow(X)
```

Using your function `orthogonal_projection` orthogonally project onto the column space of X by projecting y on each vector of X individually and adding up the projections and call the sum `yhat_naive`.

```{r}
yhat_naive = matrix(0, nrow = n, ncol = 1)
for(j in 1:p_plus_one){
  yhat_naive = yhat_naive + orthogonal_projection(y, X[,j])$a_parallel
}
```

How much double counting occurred? Measure the magnitude relative to the true LS orthogonal projection.

```{r}
yhat = lm(medv ~ ., MASS::Boston)$fitted.values
print(sqrt(sum(yhat_naive^2)) / sqrt(sum(yhat^2)))
```

Is this ratio expected? Why or why not?

#TO-DO

Convert X into V where V has the same column space as X but has orthogonal columns. You can use the function `orthogonal_projection`. This is the Gram-Schmidt orthogonalization algorithm (part A).

```{r}
V = matrix(NA, nrow = n, ncol = p_plus_one)
V[, 1] = X[, 1]
for (j in 2 : ncol(X)){
  V[, j] = X[, j]
  
  for (k in 1:(j-1)){
    v_k = V[, k]
    V[, j] = V[, j, drop = FALSE] - orthogonal_projection(X[,k], v_k)$a_parallel 
  }
}
```

Convert V into Q whose columns are the same except normalized. This is the Gram-Schmidt orthogonalization algorithm (part B).

```{r}
Q = matrix(NA, nrow = n, ncol = p_plus_one)
for(j in 1 : p_plus_one){
  Q[, j] = V[, j] / sqrt(sum(V[, j]^2))
}
rm(V)
```

Verify Q^T Q is I_{p+1} i.e. Q is an orthonormal matrix.

```{r}
#TO-DO
# expect_equal(t(Q) %*% Q, diag(p_plus_one))
# print("...")
```

Is your Q the same as what results from R's built-in QR-decomposition function?

```{r}
Q_from_Rs_builtin = qr.Q(qr(X))
# expect_equal(Q, Q_from_Rs_builtin)
```
 
Is this expected? Why did this happen?

#TO-DO
There was no output from expect_equal meaning we successfully remade our Q properly.

Project y onto colsp[Q] and verify it is the same as the OLS fit. You may have to use the function `unname` to compare the vectors since they the entries will likely have different names.

```{r}
#TO-DO
# y_hat_Q = Q %*% t(Q)
# y_hat_from_R = Q_from_Rs_builtin %*% t(Q_from_Rs_builtin) %*% y

# expect_equal(y_hat_Q, y_hat_from_R)
```

Project y onto colsp[Q] one by one and verify it sums to be the projection onto the whole space.

```{r}
# yhat_naive = 
```

Split the Boston Housing Data into a training set and a test set where the training set is 80% of the observations. Do so at random.

```{r}
K = 5
n_test = round(n * 1 / K)
n_train = n - n_test
#TO-DO 
#Training Data
# We're trying to find the indices that we will get onto train 
train_indices = sample(1:n, n_train, replace = FALSE )
X_train = X[train_indices, ]
y_train = y[train_indices]
# Test
test_indices = setdiff(1:n, train_indices)
X_test = X[test_indices,]
y_test = y[test_indices]
```

Fit an OLS model. Find the s_e in sample and out of sample. Which one is greater? Note: we are now using s_e and not RMSE since RMSE has the n-(p + 1) in the denominator not n-1 which attempts to de-bias the error estimate by inflating the estimate when overfitting in high p. Again, we're just using `sd(e)`, the sample standard deviation of the residuals.

```{r}
#TO-DO
b = solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train
y_hat_train = X_train %*% b 
e_train = y_train - y_hat_train
RMSE_e_train = sd(e_train)

y_hat_test = X_test %*% b
e_test = y_test - y_hat_test 
RMSE_e_test = sd(e_test)

```

Do these two exercises `Nsim = 1000` times and find the average difference between s_e and ooss_e. 

```{r}
#TO-DO
#TO-DO
Nsim = 1000
RMSE_trains = array(NA, Nsim)
RMSE_tests = array(NA, Nsim)

for(nsim in 1 : Nsim){
  train_indices = sample(1:n, n_train, replace = FALSE )
  X_train = X[train_indices, ]
  y_train = y[train_indices]

  test_indices = setdiff(1:n, train_indices)
  X_test = X[test_indices,]
  y_test = y[test_indices]
  
  b = solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train
  y_hat_train = X_train %*% b 
  e_train = y_train - y_hat_train
  RMSE_trains[nsim] = sd(e_train)
  
  y_hat_test = X_test %*% b
  e_test = y_test - y_hat_test 
  RMSE_tests[nsim] = sd(e_test)
  
  
}

  mean(RMSE_trains)
  mean(RMSE_tests)
```

We'll now add random junk to the data so that `p_plus_one = n_train` and create a new data matrix `X_with_junk.`

```{r}
X_with_junk = cbind(X, matrix(rnorm(n * (n_train - p_plus_one)), nrow = n))
dim(X)
dim(X_with_junk)
```

Repeat the exercise above measuring the average s_e and ooss_e but this time record these metrics by number of features used. That is, do it for the first column of `X_with_junk` (the intercept column), then do it for the first and second columns, then the first three columns, etc until you do it for all columns of `X_with_junk`. Save these in `s_e_by_p` and `ooss_e_by_p`.


```{r}
#TO-DO
# s_e_by_p = array(NA, n_train)
# ooss_e_by_p = array(NA, n_train)
# X_with_junk_train = X_with_junk[train_indices, ]
# y_train = y[train_indices]
# X_with_junk_test = X_with_junk[test_indices, ]
# y_test = y[test_indices]

# for (j in 1:n_train) {
  # y_hat_test = X_with_junk_test[, 1:j, drop = FALSE] %*% b
  # e_test = y_test - y_hat_test
  # ooss_e_by_p[j] = sd(e_test)
# }
```

You can graph them here:

```{r}
# pacman::p_load(ggplot2)
# ggplot(
  # rbind(
    # data.frame(s_e = s_e_by_p, p = 1 : n_train, series = "in-sample"),
    # data.frame(s_e = ooss_e_by_p, p = 1 : n_train, series = "out-of-sample")
  # )) +
  # geom_line(aes(x = p, y = s_e, col = series))
```
 
Is this shape expected? Explain.

#TO-DO
The in sample error decreases as we increases the number of features. The out of sample error increases as the more features we put because which signals that overfitting is happening. 

Now repeat the exercise above except use 5-fold CV (K=5 cross validation) for each p. The code below will also plot the oos RMSE. This oos RMSE curve should be similar to the curve in the above problem, but now it will be more stable. 


```{r}
K = 5
#oos_e_by_p_k = matrix(NA, nrow = n, ncol = n) #save all residuals here - each row are the residuals for number of features = j


set.seed(1984)
temp = rnorm(n)
folds_vec = cut(temp, breaks=quantile(temp, seq(0, 1, length.out=K+1)), include.lowest=TRUE, labels=FALSE)
head(folds_vec, 100)

min_ntrain = min(n - table(folds_vec))

ooss_e_by_p = array(NA, min_ntrain)
oos_se_by_p_by_k = matrix(NA, nrow = min_ntrain, ncol = K)


for (j in 1:min_ntrain) {
  all_e_test = array(NA, n)
  
      for (k in 1:K) {
      # Test train split 
      test_indices = which(folds_vec == k)
      train_indices = setdiff(1:n, test_indices)
      
      #Extract X_train, y_train, X_test, y_test
      X_with_junk_train = X_with_junk[train_indices, ]
      y_train = y[train_indices]
      X_with_junk_test = X_with_junk[test_indices, ]
      y_test = y[test_indices]
      
      X_with_junk_train_j = X_with_junk_train[ , 1:j, drop = FALSE]
      b = solve(t(X_with_junk_train_j) %*% X_with_junk_train_j) %*% t(X_with_junk_train_j) %*% y_train
      yhat_test = X_with_junk_test[, 1:j, drop=FALSE] %*% b
      
      e_k = y_test - yhat_test
      all_e_test[test_indices] = e_k
      oos_se_by_p_by_k[j,k] = sd(e_k)
    }
  ooss_e_by_p[j] = sd(all_e_test)
}



```
```{r}
#now plot it
pacman::p_load(ggplot2)
ggplot(data.frame(
    s_e = ooss_e_by_p,
    p = 1 : min_ntrain
  )) +
  geom_line(aes(x = p, y = s_e))

```


Even though the concept of confidence intervals (CIs) will not be on the midterm, construct 95% CIs for each of the oosRMSE measurements by number of features, p. A CI is a real-number interval with a lower bound and upper bound. The formula for the CI is [s_e - 2 * s_s_e, s_e + 2 * s_s_e].


```{r}
#TO-DO
s_s_es_by_j = apply(oos_se_by_p_by_k, 1, sd)
cbind(
 ooss_e_by_p - 2 * s_s_es_by_j / sqrt(K),
 ooss_e_by_p + 2 * s_s_es_by_j / sqrt(K)
)
```
